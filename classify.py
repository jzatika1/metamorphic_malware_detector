import argparse
import pickle
from typing import List, Tuple, Dict, Union
from utils.config_manager import config
from utils.file_operations import create_directories, get_all_file_paths
from utils.data_preprocessing import process_files_in_batches
from utils.hmm_training import load_model, score_file
from utils.sequence_operations import save_sequences
from utils.logger import Logger

def parse_arguments() -> argparse.Namespace:
    """Parse command-line arguments."""
    parser = argparse.ArgumentParser(description="Malware detection using HMM")
    parser.add_argument("--limit", type=int, default=None, help="Limit the number of files to load")
    parser.add_argument("--directories", nargs='+', default=['input'], help="Directories to load files from")
    parser.add_argument("--use-saved", action="store_true", help="Use saved opcode and numeric sequences for classification")
    parser.add_argument("--debug", action="store_true", help="Enable debug logging")
    return parser.parse_args()

def save_classification_sequences(opcode_sequences: List[List[str]], numeric_sequences: List[List[int]], opcode_map: Dict[Union[bytes, int], int], file_paths: List[str], file_sequence_lengths: Dict[str, List[int]]):
    """Save processed classification sequences to file for faster future loading."""
    logger = Logger.setup('classify_save')
    logger.info("Saving classification sequences")
    data = {
        'opcode_sequences': opcode_sequences,
        'numeric_sequences': numeric_sequences,
        'opcode_map': opcode_map,
        'file_paths': file_paths,
        'file_sequence_lengths': file_sequence_lengths
    }
    save_path = config.get('classification.sequences_file', 'models/classification_sequences.pkl')
    with open(save_path, 'wb') as f:
        pickle.dump(data, f)
    logger.info(f"Classification sequences saved to {save_path}")
    logger.debug(f"Saved {len(opcode_sequences)} opcode sequences, {len(numeric_sequences)} numeric sequences, and {len(file_paths)} file paths")

def load_classification_sequences():
    """Load processed classification sequences from file."""
    logger = Logger.setup('classify_load')
    logger.info("Loading classification sequences")
    load_path = config.get('classification.sequences_file', 'models/classification_sequences.pkl')
    with open(load_path, 'rb') as f:
        data = pickle.load(f)
    logger.info(f"Classification sequences loaded from {load_path}")
    logger.debug(f"Loaded {len(data['opcode_sequences'])} opcode sequences, {len(data['numeric_sequences'])} numeric sequences, and {len(data['file_paths'])} file paths")
    return data['opcode_sequences'], data['numeric_sequences'], data['opcode_map'], data['file_paths'], data['file_sequence_lengths']

def main() -> None:
    """Main function to run the malware classification process."""
    args = parse_arguments()
    Logger.set_global_debug_mode(args.debug)  # Set global debug mode
    logger = Logger.setup('classify')

    logger.info("Starting malware classification process")
    create_directories()

    if args.use_saved:
        logger.info("Using saved classification sequences")
        all_opcode_sequences, all_numeric_sequences, opcode_map, file_paths, file_sequence_lengths = load_classification_sequences()
    else:
        logger.info("Processing new files for classification")
        file_paths = get_all_file_paths(args.directories, limit=args.limit)

        if not file_paths:
            logger.warning("No files found for classification. Exiting.")
            return

        logger.info(f"Found {len(file_paths)} files for classification")
        batch_size = config.get('classification.batch_size', 1000)
        logger.info(f"Processing files in batches of {batch_size}")

        hmm_model = load_model(config.get('model.trained_hmm_file', 'models/trained_hmm.pkl'))
        all_opcode_sequences, all_numeric_sequences, opcode_map, file_sequence_lengths = process_files_in_batches(file_paths, batch_size, remove_duplicates=False)
        save_classification_sequences(all_opcode_sequences, all_numeric_sequences, opcode_map, file_paths, file_sequence_lengths)

    logger.info("Loading HMM model for classification")
    hmm_model = load_model(config.get('model.trained_hmm_file', 'models/trained_hmm.pkl'))

    scores = {}
    classifications = {}
    threshold = config.get('classification.threshold', -2.30)
    logger.info(f"Classification threshold set to {threshold}")

    start_index = 0
    for file_path, lengths in file_sequence_lengths.items():
        logger.info(f"Classifying file: {file_path}")
        end_index = start_index + len(lengths)
        file_sequences = all_numeric_sequences[start_index:end_index]
        
        score, is_malicious = score_file(hmm_model, file_sequences, threshold)
        scores[file_path] = score
        classifications[file_path] = is_malicious
        logger.info(f"File: {file_path}, Score: {score}, Malicious: {is_malicious}")
        
        start_index = end_index

    output_file = config.get('classification.output_file', 'output/classification_results.txt')
    logger.info(f"Writing classification results to {output_file}")
    with open(output_file, 'w') as f:
        f.write(f"Threshold: {threshold}\n\n")
        for file_path, score in scores.items():
            f.write(f"File: {file_path}\n")
            f.write(f"Score: {score}\n")
            f.write(f"Malicious: {classifications[file_path]}\n\n")

    total_files = len(scores)
    if total_files > 0:
        malicious_files = sum(classifications.values())
        benign_files = total_files - malicious_files
        logger.info(f"Classification complete. Total files: {total_files}, Malicious: {malicious_files}, Benign: {benign_files}")
        logger.info(f"Malicious file percentage: {(malicious_files / total_files) * 100:.2f}%")
    else:
        logger.warning("No files were classified.")

    logger.info("Malware classification process completed")

if __name__ == "__main__":
    main()