import pickle
import logging
import os
import re
import mmap

from typing import List, Tuple, Dict, Any
from multiprocessing import Pool, cpu_count
from utils.config_manager import config
from typing import List, Set

def save_file(data_and_path: Tuple[Any, str]) -> None:
    """Save an object to a pickle file."""
    data, file_path = data_and_path
    process_id = os.getpid()
    print(f"Process {process_id} saving file: {file_path}")
    with open(file_path, 'wb') as f:
        pickle.dump(data, f)

def load_file(file_path: str) -> Any:
    """Load an object from a pickle file."""
    process_id = os.getpid()
    print(f"Process {process_id} loading file: {file_path}")
    with open(file_path, 'rb') as f:
        return pickle.load(f)

def parallel_file_operation(operation: str, data_and_paths: List[Tuple[Any, str]]) -> List[Any]:
    """
    Perform parallel file operations (save or load) using all available CPUs.
    
    Args:
        operation (str): Either 'save' or 'load'.
        data_and_paths (List[Tuple[Any, str]]): List of tuples containing data (or None for load) and file paths.
    
    Returns:
        List[Any]: List of loaded objects if operation is 'load', else an empty list.
    """
    operation_func = save_file if operation == 'save' else load_file
    input_data = data_and_paths if operation == 'save' else [path for _, path in data_and_paths]

    # Determine the number of processes based on CPU count and number of files
    num_processes = min(cpu_count(), len(input_data))
    print(f"Number of processes: {num_processes}")
    print(f"Main process ID: {os.getpid()}")
    
    with Pool(processes=num_processes) as pool:
        print("Pool created. Starting parallel operation.")
        if operation == 'load':
            results = pool.map(operation_func, input_data)
        else:  # 'save'
            pool.map(operation_func, input_data)
            results = []
        print("Parallel operation completed.")

    return results

def save_sequences(opcode_sequences: List[List[str]], numeric_sequences: List[List[int]], opcode_map: Dict[str, int]) -> None:
    """
    Save opcode sequences, numeric sequences, and opcode map to files using parallel processing.
    
    Args:
        opcode_sequences (List[List[str]]): List of opcode sequences.
        numeric_sequences (List[List[int]]): List of numeric sequences.
        opcode_map (Dict[str, int]): Mapping of opcodes to numeric values.
    """
    data_and_paths = [
        (opcode_sequences, config.get('model.opcode_sequences_file', 'models/all_opcode_sequences.pkl')),
        (numeric_sequences, config.get('model.numeric_sequences_file', 'models/all_numeric_sequences.pkl')),
        (opcode_map, config.get('model.opcode_map_file', 'models/opcode_map.pkl'))
    ]
    
    parallel_file_operation('save', data_and_paths)
    logging.info("Saved all opcode sequences, numeric sequences, and opcode map using parallel processing")

def load_sequences() -> Tuple[List[List[str]], List[List[int]], Dict[str, int]]:
    """
    Load opcode sequences, numeric sequences, and opcode map from files using all available CPUs.
    
    Returns:
        Tuple[List[List[str]], List[List[int]], Dict[str, int]]: 
            - List of opcode sequences
            - List of numeric sequences
            - Opcode to numeric mapping
    """
    data_and_paths = [
        (None, config.get('model.opcode_sequences_file', 'models/all_opcode_sequences.pkl')),
        (None, config.get('model.numeric_sequences_file', 'models/all_numeric_sequences.pkl')),
        (None, config.get('model.opcode_map_file', 'models/opcode_map.pkl'))
    ]
    
    results = parallel_file_operation('load', data_and_paths)
    
    opcode_sequences, numeric_sequences, opcode_map = results
    logging.info("Loaded all opcode sequences, numeric sequences, and opcode map using parallel processing")
    return opcode_sequences, numeric_sequences, opcode_map

# Convert valid_opcodes to a set for faster lookup
valid_opcodes: Set[bytes] = {op.encode('ascii') for op in {
    'mov', 'add', 'sub', 'mul', 'div', 'jmp', 'je', 'jne', 'jg', 'jge', 'jl', 'jle',
    'call', 'ret', 'push', 'pop', 'inc', 'dec', 'cmp', 'and', 'or', 'xor', 'not',
    'shl', 'shr', 'lea', 'nop', 'int', 'movzx', 'movsx', 'test', 'xchg', 'jmp', 'jz', 'jnz',
    'jb', 'jnb', 'ja', 'jna', 'jc', 'jnc', 'jo', 'jno', 'js', 'jns', 'loop', 'loopz', 'loopnz',
    'out', 'in', 'sti', 'cli', 'cmc', 'clc', 'stc', 'cld', 'std', 'lahf', 'sahf', 'pushf', 'popf',
    'pusha', 'popa', 'daa', 'das', 'aaa', 'aas', 'cbw', 'cwd', 'cdq', 'cwde', 'aad', 'aam', 'sal',
    'sar', 'rcl', 'rcr', 'rol', 'ror', 'hlt', 'wait', 'esc', 'lock', 'rep', 'repe', 'repne', 'repnz',
    'repz', 'cmpsb', 'cmpsd', 'cmpsw', 'insb', 'insd', 'insw', 'lodsb', 'lodsd', 'lodsw', 'movsb',
    'movsd', 'movsw', 'outsb', 'outsd', 'outsw', 'scasb', 'scasd', 'scasw', 'stosb', 'stosd', 'stosw',
    'bound', 'arpl', 'sgdt', 'sidt', 'lgdt', 'lidt', 'smsw', 'lmsw', 'clts', 'invd', 'wbinvd', 'prefetch',
    'prefetchnta', 'prefetcht0', 'prefetcht1', 'prefetcht2', 'fadd', 'faddp', 'fiadd', 'fsub', 'fsubp',
    'fisub', 'fsubr', 'fsubrp', 'fisubr', 'fmul', 'fmulp', 'fimul', 'fdiv', 'fdivp', 'fidiv', 'fdivr',
    'fdivrp', 'fidivr', 'fsqrt', 'fabs', 'fchs', 'frndint', 'fscale', 'fsin', 'fcos', 'fsincos', 'fptan',
    'fpatan', 'f2xm1', 'fyl2x', 'fyl2xp1', 'fnop', 'finit', 'fclex', 'fdecstp', 'fincstp', 'ffree',
    'fnstenv', 'fldenv', 'fnstcw', 'fldcw', 'fst', 'fstp', 'fld', 'fstenv', 'fxch', 'fcom', 'fcomp',
    'fucom', 'fucomp', 'fcompp', 'fucompp', 'frstor', 'fsave', 'fstsw', 'fist', 'fistp', 'fild', 'ficom',
    'ficomp', 'fcmovb', 'fcmovbe', 'fcmove', 'fcmovnb', 'fcmovnbe', 'fcmovne', 'fcmovu', 'fcmovnu',
    'fsetpm', 'finit', 'fninit', 'fsave', 'fnsave', 'frstor', 'fnstsw', 'fclex', 'fnclex', 'fucomi',
    'fcomi', 'fxrstor', 'fxsave', 'ffreep', 'fucomip', 'fcomip', 'retf', 'iret', 'callf', 'loopne', 
    'loope', 'stc', 'clc', 'cli', 'sti', 'cld', 'std', 'lahf', 'sahf', 'popf', 'pushf', 'pusha', 'popa'
}}

# Compile regex patterns once
opcode_pattern = re.compile(rb'\b([a-z][a-z0-9]*)\b')
proc_endp_pattern = re.compile(rb'\b(proc|endp)\b', re.IGNORECASE)

def extract_opcode_sequences(file_path: str) -> List[List[bytes]]:
    """
    Extract opcode sequences from a given file using memory mapping for ultra-fast processing.
    
    Args:
        file_path (str): Path to the file to extract opcodes from.
    
    Returns:
        List[List[bytes]]: List of opcode sequences extracted from the file.
    """
    logging.info(f"Extracting opcode sequences from file: {file_path}")
    
    functions = []
    current_function = []
    total_lines = 0
    valid_lines = 0
    total_opcodes = 0

    try:
        with open(file_path, 'rb') as file:
            with mmap.mmap(file.fileno(), 0, access=mmap.ACCESS_READ) as mm:
                for line in iter(mm.readline, b''):
                    total_lines += 1
                    if proc_endp_pattern.search(line):
                        if current_function:
                            functions.append(current_function)
                            current_function = []
                    else:
                        opcodes = [op for op in opcode_pattern.findall(line.lower()) 
                                   if op in valid_opcodes]
                        if opcodes:
                            valid_lines += 1
                            total_opcodes += len(opcodes)
                            current_function.extend(opcodes)

        if current_function:
            functions.append(current_function)

    except Exception as e:
        logging.error(f"Error processing file {file_path}: {str(e)}")

    # Filter out empty functions and those with less than 2 opcodes
    valid_functions = [func for func in functions if len(func) >= 5]

    logging.debug(f"File statistics for {file_path}:")
    logging.debug(f"  Total lines processed: {total_lines}")
    logging.debug(f"  Lines with valid opcodes: {valid_lines}")
    logging.debug(f"  Total opcodes found: {total_opcodes}")
    logging.debug(f"  Functions extracted: {len(functions)}")
    logging.debug(f"  Valid functions (>= 2 opcodes): {len(valid_functions)}")

    if not valid_functions:
        logging.warning(f"No valid functions with opcodes found in file: {file_path}")
        # Log the first few lines of the file for debugging
        with open(file_path, 'rb') as file:
            first_lines = file.readlines()[:10]
        logging.debug("First 10 lines of the file:")
        for i, line in enumerate(first_lines):
            logging.debug(f"  Line {i+1}: {line.strip().decode('latin-1', errors='replace')}")

    return valid_functions