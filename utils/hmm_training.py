import logging
import pickle
import numpy as np
from collections import Counter
from typing import List, Tuple, Union, Dict
from hmmlearn import hmm
from utils.config_manager import config

def print_data_statistics(opcode_sequences, opcodes_combined, unique_opcodes, lengths):
    print("Sample of combined opcodes (first 20 elements):")
    print(opcodes_combined[:20])
    
    print("\nShape of combined opcodes:")
    print(opcodes_combined.shape)
    
    print("\nNumber of sequences:")
    print(len(opcode_sequences))
    
    print("\nLength of each sequence (first 10):")
    print(lengths[:10])
    
    print("\nUnique opcodes:")
    print(unique_opcodes)
    print(f"Total number of unique opcodes: {len(unique_opcodes)}")
    
    print("\nMost common opcodes (top 10):")
    opcode_counts = Counter(opcodes_combined)
    print(opcode_counts.most_common(10))
    
    print("\nLeast common opcodes (bottom 10):")
    print(opcode_counts.most_common()[-10:])
    
    print("\nBasic statistics:")
    print(f"Min opcode: {np.min(opcodes_combined)}")
    print(f"Max opcode: {np.max(opcodes_combined)}")
    print(f"Mean opcode: {np.mean(opcodes_combined)}")
    print(f"Median opcode: {np.median(opcodes_combined)}")
    
    print("\nTransition statistics (top 10 most common transitions):")
    transitions = Counter(zip(opcodes_combined[:-1], opcodes_combined[1:]))
    print(transitions.most_common(10))

def train_hmm(opcode_sequences: List[List[int]], n_states: int, n_iter: int, random_seed: int, thresh: float, verbose: bool):
    """
    Train an HMM model on the given opcode sequences with enhanced debugging prints and error handling.
    """
    logging.info(f"Training HMM with {n_states} hidden states")
    np.set_printoptions(threshold=np.inf, suppress=True)
    
    print("\n--- Input Data Analysis ---")
    print(f"Number of input sequences: {len(opcode_sequences)}")
    print(f"Sample of first sequence (up to 20 elements): {opcode_sequences[0][:20]}")
    print(f"Lengths of first 5 sequences: {[len(seq) for seq in opcode_sequences[:5]]}")
    
    # Combine all opcodes into a single array
    opcodes_combined = np.concatenate([np.array(seq) for seq in opcode_sequences])
    
    # Extract unique opcodes
    unique_opcodes = np.unique(opcodes_combined)
    
    # Create the opcode to index mapping
    opcode_to_index = {op: i for i, op in enumerate(unique_opcodes)}
    print("\n--- Opcode to Index Mapping ---")
    print(opcode_to_index)
    
    # Get lengths
    lengths = [len(seq) for seq in opcode_sequences]
    
    print("\n--- Detailed Data Statistics ---")
    print_data_statistics(opcode_sequences, opcodes_combined, unique_opcodes, lengths)
    
    # Convert sequences to index representation and reshape
    X = np.array([opcode_to_index[op] for seq in opcode_sequences for op in seq]).reshape(-1, 1)
    print("\n--- Preprocessed Data Information ---")
    print("Shape of X:", X.shape)
    print("Max value in X:", X.max())
    print("Number of unique values in X:", len(np.unique(X)))
    print("Sample of X (first 20 elements):", X[:20].flatten())
    
    # Initialize the model using CategoricalHMM
    model = hmm.CategoricalHMM(n_components=n_states, n_iter=n_iter, random_state=random_seed, verbose=verbose, tol=thresh)
    
    print("\n--- Initial Model Parameters ---")
    print("Note: Initial parameters are not accessible before fitting the model.")
    print(f"Number of states: {model.n_components}")
    print(f"Number of iterations: {model.n_iter}")
    print(f"Random seed: {model.random_state}")
    print(f"Convergence threshold: {model.tol}")
    
    # Fit the model
    print("\n--- Starting Model Fitting ---")
    model.fit(X, lengths)
    
    print("\n--- Final Model Parameters ---")
    if hasattr(model, 'startprob_'):
        print("Final startprob_:")
        print(model.startprob_)
    else:
        print("startprob_ not available")

    if hasattr(model, 'transmat_'):
        print("\nFinal transmat_:")
        print(model.transmat_)
    else:
        print("transmat_ not available")

    if hasattr(model, 'emissionprob_'):
        print("\nFinal emissionprob_:")
        print(model.emissionprob_)
    else:
        print("emissionprob_ not available")
    
    print("\n--- Model Training Statistics ---")
    if hasattr(model, 'monitor_'):
        print(f"Number of iterations performed: {model.monitor_.iter}")
        print(f"Improvement in log probability: {model.monitor_.history[-1] - model.monitor_.history[0]}")
        print(f"Convergence achieved: {'Yes' if model.monitor_.converged else 'No'}")
    else:
        print("Training statistics not available")
    
    print("\n--- Sample Decoding ---")
    sample_sequence = X[:100]  # Use the first 100 elements as a sample
    logprob, decoded_states = model.decode(sample_sequence)
    print(f"Log probability of sample sequence: {logprob}")
    print(f"Decoded states of sample sequence: {decoded_states}")
    
    print("\n--- Sample Generation ---")
    sample_length = 50
    generated_sample, generated_states = model.sample(sample_length)
    print(f"Generated sample (indices): {generated_sample.flatten()}")
    print(f"Generated states: {generated_states}")
    
    print("\n--- Model Evaluation ---")
    test_sequence = X[-1000:]  # Use the last 1000 elements as a test sequence
    test_logprob = model.score(test_sequence)
    print(f"Log probability of test sequence: {test_logprob}")
    
    logging.info("HMM training complete")
    return model

def save_model(model, file_path: str) -> None:
    """
    Save the trained HMM model to a file.

    Args:
        model: Trained HMM model.
        file_path (str): Path to save the model.
    """
    with open(file_path, 'wb') as file:
        pickle.dump(model, file)
    logging.info(f"Model saved to {file_path}")

def load_model(file_path: str):
    """
    Load the trained HMM model from a file.

    Args:
        file_path (str): Path to the saved model file.

    Returns:
        hmm.MultinomialHMM: Loaded HMM model.
    """
    try:
        with open(file_path, 'rb') as file:
            model = pickle.load(file)
        logging.info(f"HMM model loaded from {file_path}")
        return model
    except Exception as e:
        logging.error(f"Error loading HMM model: {e}")
        raise

def train_and_save_hmm_model(numeric_sequences: List[List[int]]) -> None:
    """
    Train an HMM model on the given numeric sequences and save it.

    Args:
        numeric_sequences (List[List[int]]): List of numeric sequences to train on.
    """
    try:
        # Retrieve parameters from config
        n_states = config.get('model.hmm.n_states', 4)
        n_iter = config.get('model.hmm.n_iter', 1000)
        tol = config.get('model.hmm.tol', 0.01)
        random_seed = config.get('model.hmm.random_seed', 0)
        verbose = config.get('model.hmm.verbose', True)
        algorithm = config.get('model.hmm.algorithm', 'viterbi')
        
        # Train the HMM model
        hmm_model = train_hmm(numeric_sequences, n_states, n_iter=n_iter, random_seed=random_seed, thresh=tol, verbose=verbose)

        # Save the trained HMM model
        save_model(hmm_model, config.get('model.trained_hmm_file', 'models/trained_hmm.pkl'))
        logging.info("HMM model trained and saved successfully")
    except Exception as e:
        logging.error(f"Error training HMM model: {e}")
        raise

def score_file(hmm_model, opcode_sequences: Union[List[List[int]], List[int]], threshold: float = -5.0) -> Tuple[float, bool]:
    """
    Score a file using the HMM model and determine if it's malicious.
    Args:
        hmm_model: Trained HMM model.
        opcode_sequences (Union[List[List[int]], List[int]]): List of numeric opcode sequences or a single sequence.
        threshold (float): Threshold for determining maliciousness.
    Returns:
        Tuple[float, bool]: Average normalized log probability score and maliciousness flag.
    """
    total_normalized_logprob = 0
    sequence_count = 0
    skipped_sequences = 0
    
    # Check if opcode_sequences is a single sequence or a list of sequences
    if isinstance(opcode_sequences[0], int):
        opcode_sequences = [opcode_sequences]  # Wrap single sequence in a list
    
    print(f"Processing {len(opcode_sequences)} sequences")
    
    for i, sequence in enumerate(opcode_sequences):
        try:
            sequence_array = np.array(sequence).reshape(-1, 1)
            logprob = hmm_model.score(sequence_array)
            sequence_length = len(sequence)
            normalized_logprob = logprob / sequence_length if sequence_length > 0 else logprob
            print(f"Sequence {i+1}: Length = {sequence_length}, Log probability = {logprob:.4f}, Normalized = {normalized_logprob:.4f}")
            total_normalized_logprob += normalized_logprob
            sequence_count += 1
        except IndexError as e:
            skipped_sequences += 1
            print(f"Skipped sequence {i+1} due to unknown opcode: {str(e)}")
            continue

    if sequence_count > 0:
        average_normalized_logprob = total_normalized_logprob / sequence_count
        print(f"\nAverage normalized log probability: {average_normalized_logprob:.4f}")
        is_malicious = average_normalized_logprob > threshold
        print(f"Classification: {'Malicious' if is_malicious else 'Benign'} (Threshold: {threshold})")
    else:
        print("\nNo valid sequences to score")
        average_normalized_logprob = float('-inf')
        is_malicious = False

    print(f"Total sequences: {len(opcode_sequences)}, Scored: {sequence_count}, Skipped: {skipped_sequences}")
    return average_normalized_logprob, is_malicious

def score_file_sequences(hmm_model, numeric_sequences: List[List[int]], file_sequence_lengths: Dict[str, List[int]], threshold: float) -> Dict[str, Tuple[float, bool]]:
    """
    Score sequences for each file based on file sequence lengths.
    
    Args:
        hmm_model: The trained HMM model.
        numeric_sequences (List[List[int]]): All numeric sequences.
        file_sequence_lengths (Dict[str, List[int]]): Dictionary of file paths to their sequence lengths.
        threshold (float): Classification threshold.
    
    Returns:
        Dict[str, Tuple[float, bool]]: Dictionary of file paths to their scores and classifications.
    """
    results = {}
    start_index = 0
    for file_path, lengths in file_sequence_lengths.items():
        print(f"\nScoring file: {file_path}")
        end_index = start_index + len(lengths)
        file_sequences = numeric_sequences[start_index:end_index]
        score, is_malicious = score_file(hmm_model, file_sequences, threshold)
        results[file_path] = (score, is_malicious)
        start_index = end_index
    return results