data:
  train_dir: 'data'
  test_dir: 'input'
preprocessing:
  batch_size: 5000
model:
  hmm:
    n_states: 12                # Number of hidden states
    n_iter: 10000               # Number of iterations for training
    tol: 0.01                   # Convergence threshold
    algorithm: 'viterbi'        # Algorithm to use
    random_seed: 0              # Random seed for reproducibility
    verbose: True               # Verbosity level for training
  trained_hmm_file: 'models/trained_hmm.pkl'  # Path to save/load trained HMM model
logging:
  level: 'INFO'
  file: 'logging/app.log'
classification:
  output_file: 'output/classification_results.txt'  # Path to save classification results
  sequences_file: 'models/classification_sequences.pkl'  # Path to save/load processed sequences
  threshold: -2.30  # Classification threshold
  batch_size: 1000  # Batch size for processing files during classification